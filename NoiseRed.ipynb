{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "✅ 1. Skini podatke \\\n",
    "✅ 2. Izdvoji train i test\\\n",
    "✅ 3. Analiza train skupa\\\n",
    "✅ 4. Normalizacija/standardizacija\\\n",
    "✅ 5. Vizuelizacija\\\n",
    "✅ 6. Dodavanje suma\n",
    "\n",
    "------\n",
    "✅ 1. Rez kao matrica + granice odlucivanja \\\n",
    "✅ 2. Baseline performanse - par modela\\\n",
    "✅ 3. Regularizacija modela + sve iz prvog koraka\\\n",
    "✅ 4. Dim reduction + 1. korak\\\n",
    "✅ 5. Otklanjanje outlier + 1. korak\\\n",
    "✅ 6. Redukcija suma atributa + 1. korak\\\n",
    "8. Otklanjanje suma labela + 1. korak\\\n",
    "8. OvO vs OvA\\\n",
    "9. Modeli otporni na sum\\\n",
    "10. Autoencoder za denoising?\n",
    "\n",
    "- Ubaci da iscrta sve heatmape sa odgov. naslovom - da bi uporedio base, +reg, +dimred..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub openpyxl imbalanced-learn seaborn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub as kg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from helper.plot import plot_attr_label, plot_attributes\n",
    "from helper.model import MLP\n",
    "from helper.transform import transform_pca, remove_outliers_zscore, remove_outliers_db, remove_outliers_isf, bin_attributes, regression_reduce_noise\n",
    "from helper.train import run_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kg.dataset_download(\"muratkokludataset/dry-bean-dataset\")\n",
    "file_name = '/Dry_Bean_Dataset/Dry_Bean_Dataset.xlsx'\n",
    "print(\"Downloaded at: \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(class_count, class_ind):\n",
    "    rez = np.zeros(class_count)\n",
    "    rez[class_ind] = 1\n",
    "    return rez\n",
    "\n",
    "unique_vals = np.unique(data['Class'])\n",
    "class_map_oh = {x: get_onehot(len(unique_vals), i) for i, x in enumerate(unique_vals)}\n",
    "class_map_label = {x: i for i, x in enumerate(unique_vals)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class_OneHot'] = data['Class'].apply(lambda x: class_map_oh[x])\n",
    "data['Class_Label'] = data['Class'].apply(lambda x: class_map_label[x])\n",
    "data.drop(axis=1, labels=['Class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odmah izdvajamo train i test set u razmeri 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc = 0.8\n",
    "test_perc = 1 - train_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=test_perc, random_state=42)\n",
    "\n",
    "# Perform the split\n",
    "for train_idx, test_idx in split.split(data, data['Class_Label']):\n",
    "    train_set = data.iloc[train_idx]\n",
    "    test_set = data.iloc[test_idx]\n",
    "\n",
    "print('Train size: ', len(train_set), 'x', len(train_set.iloc[0]))\n",
    "print('Test size: ', len(test_set), 'x', len(test_set.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributi \n",
    "- Area\n",
    "- Perimeter\n",
    "- Major Axis Length\n",
    "- Minor Axis Length\n",
    "- AspectRation\n",
    "- ConvexArea\n",
    "- EquivDiameter \n",
    "\n",
    "imaju dosta velike vrednosti dok ostali atributi su u range $[0-1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attributes(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa grafikona vidimo da vrednosti atributa ne prate normalnu raspodelu.\\\n",
    "Atributi kao ShapeFactor4 i Solidity imaju velike repove. Zato ćemo tokom preprocesiranja normalizovati raspodele.\\\n",
    "Pored toga skup podataka nije balansiran:\n",
    "- Klasa 1 je slabo zastupljena sa manje od 500 instanci, klasa 0 ima oko 1000 dok klasa 3 dominira sa oko 2500 instanci\n",
    "- Zato ćemo izvršiti under i oversampling na oko 1-1.5 hiljade instanci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attr_label(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po grafikonu iznad vidimo da se klasa 1 karakteriše visokim vrednostima Major i Minor axis length, EquivDiameter, ConvexArea, Area i Perimeter. Pored toga ima male vrednosti ShapeFactor1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#1212AA; height:auto; border-radius:10px; padding:16px; width:600px; color:white\">\n",
    "<h3>Zaključci</h3>\n",
    "<ul>\n",
    "<li>Podaci su nebalansirani, potrebno je under i over sample-ovati na oko 1-1.5 hiljade instanci</li>\n",
    "<li>Atribute je potrebno normalizovati, a neke i skalirati kao što su Area</li>\n",
    "<li>Klasa 1 je nedovoljno zastupljena ali lako prepoznatljiva po atributima koji imaju visoke vrednosti kao što je Area</li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizacija i Standardizacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oh = train_set['Class_OneHot']\n",
    "y_lab = train_set['Class_Label']\n",
    "X = train_set.drop(axis = 1, labels=['Class_OneHot','Class_Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "X_pt = pt.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_set_scaled = scaler.fit_transform(X_pt)\n",
    "X_pt = pd.DataFrame(train_set_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attributes(X_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podaci sada prate raspodele dosta bliže normalnoj raspodeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attr_label(X_pt, labels=y_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under/OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_samples = 1250 # Pick a number in the range\n",
    "\n",
    "# Oversample with SMOTE and undersample with RandomUnderSampler\n",
    "smote = SMOTE(sampling_strategy=lambda y: {k: max(target_samples, v) for k, v in Counter(y).items() if v < target_samples}, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_pt, y_lab)\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy=lambda y: {k: min(target_samples, v) for k, v in Counter(y).items() if v > target_samples}, random_state=42)\n",
    "X_resampled, y_resampled = under.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_balanced = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_balanced['target'] = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['target_oh'] = df_balanced['target'].apply(lambda x: get_onehot(len(np.unique(df_balanced['target'])), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada imamo tačno 1250 instaci u svakoj klasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#12AA12; height:auto; border-radius:10px; padding:16px; width:600px; color:white\">\n",
    "<h3>Zaključci</h3>\n",
    "<ul>\n",
    "<li>Podaci su sada izbalansirani - svaka klasa ima 1250 instanci</li>\n",
    "<li>Atribute su normalizovani i skalirani na 0-1</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline performanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = df_balanced.drop(axis=1,labels=['target','target_oh'])\n",
    "y = df_balanced['target']\n",
    "\n",
    "all_res = []\n",
    "all_res_change=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(X_t.values[0])\n",
    "rfc = (RandomForestClassifier(n_jobs=4), False)\n",
    "svc = (SVC(), False)\n",
    "gbc = (GradientBoostingClassifier(), False)\n",
    "abc = (AdaBoostClassifier(), False)\n",
    "knc = (KNeighborsClassifier(), False)\n",
    "mlp = (MLP(input_size=feature_num, hidden_size=5, output_size=len(np.unique(y))), True)\n",
    "\n",
    "models = [rfc, svc, gbc, abc, knc, mlp]\n",
    "noise_schedule = [0, 0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res, new_res_change = run_models(X_t, y, models, all_res, all_res_change, transforms=[], title=\"Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#1212AA; height:auto; border-radius:10px; padding:16px; width:1000px; color:white\">\n",
    "<h3>Zaključci</h3>\n",
    "<ul>\n",
    "<li>Kod svih modela se može primetiti da imaju poteškoća kod predviđanja instanci koje se nalaze u gustim oblastima gde ima dosta mešanja instanca različitih klasa.</li>\n",
    "<li>Potencijalno je poboljšanje sa regularizacijom modela</li>\n",
    "<li>Pored toga postoje instance koje su dosta odvojene od ostatka instance što bi moglo da reši uklanjanje outlier-a</li>\n",
    "<li>Na heatmap-i vidimo preciznost modela kao i promene u preciznosti usled povećanja šuma</li>\n",
    "<li>Svi modeli imaju dosta dobre performanse (oko 93% preciznosti) kada nema šuma, dok povećanjem šuma se preciznost smanjuje</li>\n",
    "<li>RandomForest i GradientBoosting klasifikatori su za sada najotporniji na šum labela (pad oko 15-20% kada pola skupa se zameni nasumičnim vrednostima), dok su se perceptron i KNeighbors klasifikator najgore pokazali</li>\n",
    "<li>Svi modeli imaju velik pad u preciznosti kada se pojavi šum medju labelama, što se vidi i na dijagramima sa granicama odlučivanja</li>\n",
    "<li>AdaBoost model postiže čak bolje performanse kada se unese malo šuma. Šum ovde služi kao način regularizacije modela.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizacija modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(X_t.values[0])\n",
    "rfc = (RandomForestClassifier(n_jobs=4, max_depth=4, max_features='log2'), False)\n",
    "svc = (SVC(C = 10, kernel='linear'), False)\n",
    "gbc = (GradientBoostingClassifier(max_features='log2'), False)\n",
    "abc = (AdaBoostClassifier(), False)\n",
    "knc = (KNeighborsClassifier(n_neighbors=15), False)\n",
    "mlp = (MLP(input_size=feature_num, hidden_size=5, output_size=len(np.unique(y)), l2_reg=0.005), True)\n",
    "\n",
    "models = [rfc, svc, gbc, abc, knc, mlp]\n",
    "noise_schedule = [0, 0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res, new_res_change = run_models(X_t, y, models, all_res, all_res_change, transforms=[], title=\"With regularization\")\n",
    "all_res.append((\"After regularization\", new_res))\n",
    "all_res_change.append((\"After regularization\", new_res_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#1212AA; height:auto; border-radius:10px; padding:16px; width:1000px; color:white\">\n",
    "<h3>Zaključci</h3>\n",
    "<ul>\n",
    "<li>Regularizacijom modela se u ovom slučaju ne postižu bolji rezultati, čak se često dobijaju i gori</li>\n",
    "<li>U nekim slučajevima je regularizacija poboljšala performanse, ali poboljšanja nisu značajna</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redukcija dimenzionalnosti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dalje će testiranje biti vršeno na sledeći način\n",
    "- U skup podataka se doda određena količina šuma\n",
    "- Nad trening podacima se primena neka od tehnika - PCA, uklanjanje outliera, redukcija šuma ili se nad labela primeni otklanjanje šuma labela\n",
    "- Nad tako dobijenim podacima se vrši trening i procena performansi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = 5\n",
    "rfc = (RandomForestClassifier(n_jobs=4), False)\n",
    "svc = (SVC(), False)\n",
    "gbc = (GradientBoostingClassifier(), False)\n",
    "abc = (AdaBoostClassifier(), False)\n",
    "knc = (KNeighborsClassifier(), False)\n",
    "mlp = (MLP(input_size=feature_num, hidden_size=5, output_size=len(np.unique(y))), True)\n",
    "\n",
    "models = [rfc, svc, gbc, abc, knc, mlp]\n",
    "noise_schedule = [0, 0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res, new_res_change = run_models(X_t, y, models, all_res, all_res_change, transforms=[transform_pca], title=\"With dimensionality reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#1212AA; height:auto; border-radius:10px; padding:16px; width:1000px; color:white\">\n",
    "<h3>Zaključci</h3>\n",
    "<ul>\n",
    "<li>Regularizacijom modela se u ovom slučaju ne postižu bolji rezultati, čak se često dobijaju i gori</li>\n",
    "<li>U nekim slučajevima je regularizacija poboljšala performanse, ali poboljšanja nisu značajna</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Izbacivanje outliera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = 16\n",
    "rfc = (RandomForestClassifier(n_jobs=4), False)\n",
    "svc = (SVC(), False)\n",
    "gbc = (GradientBoostingClassifier(), False)\n",
    "abc = (AdaBoostClassifier(), False)\n",
    "knc = (KNeighborsClassifier(), False)\n",
    "mlp = (MLP(input_size=feature_num, hidden_size=5, output_size=len(np.unique(y))), True)\n",
    "\n",
    "models = [rfc, svc, gbc, abc, knc, mlp]\n",
    "noise_schedule = [0, 0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res, new_res_change = run_models(X_t, y, models, all_res, all_res_change, transforms=[remove_outliers_zscore], title=\"With zscore outlier removal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res, new_res_change = run_models(X_t, y, models, all_res, all_res_change, transforms=[remove_outliers_isf], title=\"With isolation forest outlier removal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_models(X_t, y, models, all_res, all_res_change, transforms=[remove_outliers_db], title=\"With db outlier removal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redukcija šuma atributa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_models(X_t, y, models, all_res, all_res_change, transforms=[bin_attributes], title=\"attribute binning, 10 bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_models(X_t, y, models, all_res, all_res_change, transforms=[regression_reduce_noise], title=\"reduce attribute noise with regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
